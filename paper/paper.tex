\documentclass[sigplan]{acmart}
\settopmatter{printacmref=false} % Removes citation information below abstract
\renewcommand\footnotetextcopyrightpermission[1]{} % removes footnote with conference information in first column
\pagestyle{plain} % removes running headers

\usepackage[english]{babel}
\usepackage{url}
\usepackage{makecell}

\begin{document}

\title{Automatic Summarization of Scientific Texts}

\author{Maria Dobko}
\affiliation{%
  \institution{Ukrainian Catholic University\\
  Faculty of Applied Sciences}
  \city{Lviv}
  \state{Ukraine}
}
\email{dobko_m@ucu.edu.ua}

\author{Oleksandr Zaytsev}
\affiliation{%
  \institution{Ukrainian Catholic University\\
  Faculty of Applied Sciences}
  \city{Lviv}
  \state{Ukraine}
}
\email{oleks@ucu.edu.ua}

\author{Yuriy Pryima}
\affiliation{%
  \institution{Ukrainian Catholic University\\
  Faculty of Applied Sciences}
  \city{Lviv}
  \state{Ukraine}
}
\email{y.pryima@ucu.edu.ua }

\begin{abstract}

In this work we overview recent advancements in the field of abstractive text summarization and discuss the use of deep learning models, especially Generative Adversarial Networks (GAN). We apply different models to our dataset of scientifix papers, acquired from arXiv, and evaluate them in terms of simplicity and performance.

We propose our own metric based on word-embeddings, which we believe will be more suitable for evaluation of abstractive summaries.

\end{abstract}

\keywords{scientific text summarization, ROUGE, seq2seq, NLP, word embeddings}

\maketitle

\section{Introduction}

Automatic text summarization is the task of producing a concise and fluent summary while preserving key information content and overall meaning\cite{allahyari-17}.

\subsection{Abstractive vs extractive summarization}

\paragraph{Extractive text summarization}

\subsection{Abstractive summarization}

\paragraph{Abstractive text summarization} allows us to write summaries that are almost as good as those written by humans. It is closer to what humans do when they write text summaries, but also more complex. T

\subsection{Scientific text summarization}

The problem of summarizing scientific texts is very different from general-purpose text summarization. Every scientific paper starts with an abstract, which by its nature is the summary of a document created by its human-author. This allows us to can create a human-labeled dataset of scientific papers just by separating abstracts from the text body.

\subsection{Structure of the paper}

In this study we focus on abstractive text summarization. We do a brief overview of the related work that has been done in this field. Then we proceed to discussing different models for statistical and deep summarization. Then we present our dataset of scientific papers collected from arXiv and compare the performance of different models on this dataset. 

\section{Related work}

Allahyari et al.\cite{allahyari-17} make a survey of the most successful text summarization techniques as of July 2017.

This September Li et al. \cite{li-cohn-17} described their submission to the sentiment analysis sub-task of ?Build It, Break It: The Language Edition (BIBI)? where they successfully apply generative approach to the problem of sentiment analysis.

In their paper \textit{Generative Adversarial Network for Abstractive Text Summarization} Liu et al.\cite{liu-17} built an adversarial model that achieved competitive ROUGE scores with the state-of-the-art methods on CNN/Daily Mail dataset. They compare the performance of their approach with three methods, including the abstractive model, the pointer-generator coverage networks, and the abstractive deep reinforced model.

In contrast Zhang et al.\cite{zhang-17} don't use reinforcement learning but rather introduce TextGAN with an LSTM-based generator and kernelized discrepancy metric.

\section{Data collection and preparation}
\label{sec:data}

Thanks to the open policy of arXiv we were able to collect our own dataset of scientific papers from \textit{stat.ML} category\footnote{\url{https://arxiv.org/list/stat.ML/recent}}. We publish it together with this paper an encourage everyone to use it as they like in their own projects.

\paragraph{Structure of the data} Each paper on arXiv has a unique identifier (for eample: 1801.01587). It can be used to extract any data that is available and related to that paper, including its metadata and full text as PDF.

Our dataset contains 2000 documents (papers). Each one of them is represented by a row with the following properties:

\begin{enumerate}
  \item arXiv's unique identifier
  \item title
  \item abstract
  \item body of the paper
\end{enumerate}

Our script\footnote{Code and instructions for collecting the data is available in our repository: \url{https://github.com/Carouge/TextSummarization}} can be used to collect more data, but for our problem a set of 2000 papers from one category is enough. For example, DUC (Document Understanding Conference) dataset which is among the most commonly used in the feld of text summarization has 30 sets with approximately 10 documents each\footnote{\url{https://www-nlpir.nist.gov/projects/duc/guidelines/2001.html}}.

\paragraph{Cleaning the text} We collected our data as PDF files and parsed them to extract the raw text. This produced a huge amount of uniterpretable UTF-8 characters from mathematical expressions. After removing those extra characters.

We wanted to remove everething that is not a known English word, but that would filter out words like "GAN", "backprop" etc. as most standard corpuses of words, such as nltk.corpus, don't include specialized scientific terminology. So we filtered the words using manually created rules based on features like word length and frequence of vowels. This leaves some noise behind, but it will not affect our models.

\section{Models for text summarization}

Three main classes of models that are used for text summarization task are statistical frequency computation models (TFIDF etc.), graph methods (TextRank, LexRank etc.) and machine learning approach.

\subsection{Statistical methods}

These methods are based on the assumption that the importance of a word or sentence in a text depends on the total number of times it appears in the document. This means that this classical approach ignores context and lexical features of the text. Furthermore, they are able to perform only extractive summarization.

\subsection{Graph models}

We can build a graph of each document where words or sentences are nodes and the edges are the connections between each pair of nodes. The weights on these edges represent similarity between words or sentences in the whole text. While proving to have better results than simple frequency-based methods, graph models are still bounded by the absence of lexic understanding and ability to perform extractive summary only.

\subsection{Machine learning approach}

In the last years, lots of attention was focused on learning how to apply neural networks to NLP tasks, including text summarization. Using encoder-decoder models it is now possible to produce abstract summaries. In \cite{nallapati-16} the off-the-shelf attentional encoder-decoder RNN that was originally developed for machine translation was applied to summarization and outperformed state-of-the-art systems on two different English corpora. However, there is not much information about neural networks usage in scientific text summarization.

Generative adversarial networks (GAN) are another promising approach for text summarization. Until recent years they were considered inapplicable to the discrete problems of natural language processing (NLP). The latest papers introduce novel approaches to overcoming these issues by combining GANs with reinforcement learning.

Applying generative adversarial networks to the problems of NLP is considered to be a complicated task because GANs are only defined for continuous data, and all NLP is based on discrete values like words, characters, or bytes.

However, in their latest paper Fedus, Goodfellow, and Dai\cite{fedus-18} overcome this problem by using reinforcement learning to train the generator while the discriminator is still trained via maximum likelihood and stochastic gradient descent, and use it to fill the gaps in the text.


\section{Evaluation metrics}
\label{sec:evaluation}

Evaluating a summary is a difficult task because there is no such thing as a single summary that would be ideal for a given document. In most cases even human evaluators can not agree on which of the given summaries is better\cite{das-7}. Unlike other NLP problems, such as translation or parsing, when it comes to text summarization we can not clearly define what makes a summary good or bad. Therefore we must make assumptions about the space of good summaries. 

\begin{enumerate}
\item assume that a good summary would be close to some \textit{ideal} summary manually created by humans
\item assume that the goodness of summary can be measured as the ammount of important information it contains (this assumption can be infered from the definition of text summarization).
\end{enumerate}

In the following sections we briefly describe some of the commonly used metrics for text summarization that is based on the first assumption and propose our own metric that is based on second one (in fact, we will show that the proposed metric can be formulated in a different way to work with the first assumption).

\subsection{ROUGE}
\label{sec:rouge}

The most widely used score for evaluating text summarizations is ROUGE (Recall-Oriented Understudy for Gisting Evaluation) inroduced by Chin-Yew Lin in 2004\cite{lin-4}.

\[ \text{ROUGE-N}(s) = \frac{\sum_{r \in R} \langle \Phi_n(r), \Phi_n(s) \rangle}{\sum_{r \in R} \langle \Phi_n(r), \Phi_n(r) \rangle} \]

\[ \text{ROUGE-L}(s) = \frac{(1 + \beta^2) R_{LCS} P_{LCS}}{R_{LCS} + \beta^2 P_{LCS}} \]

ROUGE works well for extractive text summarization. But if we need to evaluate the generated summary which contains different words from the ones that occured in paper, the score will always be small because, even though the new words can be close to the expected ones, two summaries don't overlap in terms of word equality.

For example, if the human-created summary is \textit{"The great paper"} and our model produces \textit{"A wonderful article"}, ROUGE score will be $0$, even though the summary is perfect.

\subsection{CAROUGE}

We propose a metric that uses word embeddings to evaluate summaries based on their semmantic distance to the space of good summaries. Our assumption is that a good summary of a document contains words that are semantically close to the most important words or n-grams in that document.

Let $s$ be the generated summary. If $|s|$ is the number of words in summary $s$, then $m=|s|-n+1$ is the number of $n$-grams in this summary. Let $s_1, s_2, \dots, s_m$ be all $n$-grams of summary $s$ and let $c_1, c_2, \dots, c_k$ be the $k$ most important $n$-grams in the document. As we will show in section \ref{sec:importance}, there are many ways of measuring the importance of $n$-grams in a document. The definition of $n$-gram importance is closely related to the two base assumptions that were mentioned at the beginning of section \ref{sec:evaluation}.

The metric we propose is in fact a continuous version of ROUGE-N. Instead of testing the equality of n-grams in the compared summaries we use the continuous measure of semmantic distance between those n-grams.

For each $n$-gram in the generated summary we calculate the embedding-based score as its distance to the closest important $n$-gram in the document\footnote{CAROUGE stands for Continuous Abstractive ROUGE. The French word \textbf{carouge} means blackbird}.

\[ \text{CAROUGE-N}(s_i) = \frac{1 - \operatorname*{min}_j ||s_i - c_j||}{k} \]

Now we define the score of the whole summary as the average score of its words

\[ \text{CAROUGE-N}(s) = \frac1n \sum_{i=1}^n \frac{1 - \operatorname*{min}_j ||s_i - c_j||}{k} \]

\subsubsection{Measuring word importance}
\label{sec:importance}

To choose which words are important we can use an algorithm of extractive text summarization. We will use \textbf{term frequency-inverse document frequency} (tf-idf) as a measure of importance because of its simplicity and importance (according to \cite{kumar-16}, tf-idf is one of the universally used terminologies in extractive summarization).

Using the same example as in the section \ref{sec:rouge} we can see that CAROUGE score of a decent abstractive summary will be greater than 0.

\[ r = \text{"The great paper"} \]
\[ s = \text{"A wonderful article"} \]
\[ \text{ROUGE}(s) = 0 \]
\[ \text{CAROUGE}(s) = 0.8956 \]

\section{Experiments and results}

We have tried different methods of text summarization, both extractive (TextRank, RAKE) and abstractive (Seq2Seq, SeqGAN).

\subsection{RAKE}

Rapid Automatic Keyword Extraction algorithm (RAKE)\cite{rose-10} is a keyword extraction algorithm which tries to determine key phrases in a body of text by analyzing the frequency of word appearance and its co-occurance with other words in the text. Its main advantages include  time efﬁciency, operating on individual documents. It can be easily applied to new domains and multiple types of documents. RAKE is very sensitive to unclean data, as it relies on word frequency.

\begin{table}[H]
\caption{Example of an abstract generated by RAKE}

\begin{center}
\begin{tabular}{|p{0.25\linewidth}|p{0.67\linewidth}|}
\hline
\textbf{Title} & The Multivariate Generalised von Mises distribution: Inference and  applications \\
\hline
\textbf{Real abstract} & ...Previously proposed multivariate circular distributions are shown to be special cases of this construction. Second, we introduce a new probabilistic model for circular regression, that is inspired by Gaussian Processes, and a method for probabilistic principal component analysis with circular hidden variables... \\
\hline
\textbf{\makecell[l]{Generated \\ abstract}} & ...many data modelling problems since higher order generalised von mises distributions model circular variables using distributional assumptions probabilistic principal component analysis ppca proposed resulting distribution inherits desirable characteristics paper makes three technical contribu tions multivariate generalised... \\
\hline
\end{tabular}
\end{center}
\end{table}

\subsection{TextRank}
In this research we used a basic model TextRank as a baseline for comparison.  This is a graph method, influenced by PageRank algorithm, that represents the documents as a connected graph\cite{mihalcea-4}. We trained TextRank separately for each body of the paper and produced an extractive abstract-length summary. Scores were calculated on the basis of ROUGE score. Unlike RAKE which operates n-grams, TextRank generates summaries using whole sentences. For that reason the generated summaries are more readable.

\begin{table}[H]
\caption{Example of an abstract generated by TextRank}

\begin{center}
\begin{tabular}{|p{0.25\linewidth}|p{0.67\linewidth}|}
\hline
\textbf{Title} & Churn Prediction in Mobile Social Games: Towards a Complete Assessment Using Survival Ensembles \\
\hline
\textbf{Real abstract} & ...for each player, we predict the probability of churning as function of time, which permits to distinguish various levels of loyalty profiles ... Our results show that churn prediction by survival ensembles significantly improves the accuracy and robustness of traditional analyses, like Cox regression... \\
\hline
\textbf{\makecell[l]{Generated \\ abstract}} & Conditional inference survival ensembles are constructed based on unbiased trees avoiding this problem the resulting prediction of this model contains for each player a survival function indicating the probability of churn as a function of time since the registration in the game. \\
\hline
\end{tabular}
\end{center}
\end{table}

\subsection{Seq2Seq}
We have used deep LSTM seq2seq model with attention for a task of text summarization. Seq2seq have proven to provide state-of-art result in tasks of sequence generation. At this point it is too hard to produce an abstract from the text of a paper, so we started with a simpler task of generating a title from the text of an abstract
As input model takes paper abstract converted to the vectorized representation using word embeddings.  The input sequence is limited by 600 words. All abstracts that are bigger than limit are omitted. All smaller abstracts are padded with $\langle\text{SOS}\rangle$ word that represents the end of a sequence.
Model outputs sequence derived from the probability distribution. Each output word samples from this distribution having input sequence and previously generated samples. Output sequence is limited by 30 words. First $\langle\text{SOS}\rangle$ word represent the end of a generated summary.


\section{Evaluating results}

In the table below you can see the results of our experiments represented by mean scores over all 2000 papers from our dataset.

\begin{table}[H]
\caption{Evaluating different models with ROUGE}

% \begin{center}
% \begin{tabular}{|l|c|c|c|c|}
% \hline
% \textbf{Model} & \textbf{ROUGE-1} & \textbf{ROUGE-2} & \textbf{ROUGE-L} & \textbf{CAROUGE-1} \\
% \hline
% TextRank & 18.04 & 4.10 & 10.89 & 0 \\
% RAKE & 8.93 & 1.54 & 7.54 & 0 \\
% Human & 0 & 0 & 0 & 0 \\
% \hline
% \end{tabular}
% \end{center}
% \end{table}

\begin{center}
\begin{tabular}{|l|c|c|c|c|}
\hline
\textbf{Model} & \textbf{ROUGE-1} & \textbf{ROUGE-2} & \textbf{CAROUGE-1} \\
\hline
TextRank & 18.04 & 4.10 & 0 \\
RAKE & 8.93 & 1.54 & 0 \\
Human & 0 & 0 & 0 \\
\hline
\end{tabular}
\end{center}
\end{table}

\section*{Conclusions}

In this paper we demonstrated how Generative Adversarial Networks can be used for abstractive text summarization.

% \section*{Acknowledgements}

% We would like to express our gratitude to Anatolii Stehnii, Artem Chernodub, Maryana Romanyshyn, and Oksana Tkach for supporting us with their advices.

\bibliographystyle{plain}
\bibliography{paper}

\end{document}